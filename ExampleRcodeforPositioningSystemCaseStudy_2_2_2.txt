# Example R code for Positioning System Case Studysetwd("/Users/mmcgee/Dropbox/2016 Summer Courses/MSDS 7333/Units5and6")# Commented out after file was downloaded to local machine# URL <- "http://rdatasciencecases.org/Data/offline.final.trace.txt"# download.file(url=URL,destfile = "offlineFinalTrace.txt")options(digits = 3) #optional specification: three digits will be printed for numeric values. Default is 7.# Read in the datatxt = readLines("offlineFinalTrace.txt")# Locate lines or strings that begin with a "#" character and tally them. This is important because the "#" is the comment character in R, and any lines with this character at the beginning will not be read into R as data.sum(substr(txt, 1, 1) == "#")length(txt)strsplit(txt[4], ";")[[1]] # Examine structure the first data line#The number of expected lines (166 locations x 8 angles 6 110 recordings = 146080) is the difference between the number of total lines and the number of commented lines. Now that we understand the commented lines, we need to examine the structure of the lines. #The data are not in a data frame format. We need to get them there, but read.table() will not work since the data are not in a rectangular form. From the first line of data, we see that the data elements are split by semi-colons, and further splits within lines occur at commas and equal signs. The code below splits the data further.#This code will not read in all of the data. We were practicing on part of the data. This is a really good idea when reading in any data set. One should always make sure to understand the data structure by reading in the first few lines (or a random sample of lines). Then, one can write the code to enter the data properly. # The split parameter in strsplit can be a regular expression. We can split on several characters within a single function call - as below.tokens = strsplit(txt[4], "[;=,]")[[1]] #split at a ; = or , charactertokens[1:10] # information about the handheld devicetokens[c(2, 4, 6:8, 10)] # extract the values of these variablestokens[ - ( 1:10 ) ] # recorded signals within this observationtmp = matrix(tokens[ - (1:10) ], ncol = 4, byrow = TRUE)# Build a matrix from the recorded signalsmat = cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow = nrow(tmp),                   ncol = 6, byrow = TRUE),             tmp)dim(mat) # confirm dimension of the matrix#The object "tokens" gives us information about the pieces of the data set once the observations are split into different variables using "strsplt". The first column contains information on the time that the signal was recorded. This time is the number of milliseconds elapsed between January 1, 1970 and the time at which the recording was made. The next entry is the "id", which is the address of the access point. The position variable gives the coordinates of the user at the time of the recording, and the degree variable shows the angle of orientation of the user with respect to the access point. Signal strenghs are given as a base 2 logarithm; therefore, some of the values are negative. The next variable is the channel, followed by the mode of the device. The mode (also called "type") is either an access point or an adhoc device.#The following function repeats the above operations for each row in the input file.processLine =  function(x)  {    tokens = strsplit(x, "[;=,]")[[1]]    tmp = matrix(tokens[ - (1:10) ], ncol = 4, byrow = TRUE)    cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow = nrow(tmp),                 ncol = 6, byrow = TRUE), tmp)  }tmp = lapply(txt[4:20], processLine) # make sure it works on the first 16 linessapply(tmp, nrow) # Find the number of records per row# Turn these individual matrices into a single data frameoffline = as.data.frame(do.call("rbind", tmp)) # faster than a for loop!dim(offline)# Here we go - reading in some datalines = txt[ substr(txt, 1, 1) != "#" ]tmp = lapply(lines, processLine)## Debugging#There were several warnings. Warnings do not stop the code from running, but we can't just dismiss them. Rather, we need to  understand why these warnings have occurred. But, we don't want to try to find the six places where the warnings occurred by searching through a million lines of data. It's better to ask R to raise an error when a warning in issued and browse the call stack to determine why the error may have occurred.options(error = recover, warn = 2) # stop function when a warning occurs tmp = lapply(lines, processLine)#The problem is that some lines have no signal strength recorded. Since we cannot get these signal strengths back, and there are so few of them, we will not use these records in our analysis. The following code sets the signal strength value for those observations without signal strengh measurements to "NULL". Then, we rerun the data entry code, setting the debugging options back to the default.processLine = function(x){  tokens = strsplit(x, "[;=,]")[[1]]    if (length(tokens) == 10)   return(NULL)    tmp = matrix(tokens[ - (1:10) ], , 4, byrow = TRUE)  cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow(tmp), 6,   byrow = TRUE), tmp)}options(error = recover, warn = 1) # reset options# Create the new data settmp = lapply(lines, processLine)offline = as.data.frame(do.call("rbind", tmp), stringsAsFactors = FALSE)dim(offline)#There are over one million lines of data and ten variables. Now that the data are entered, they need to be cleaned for analysis.## Cleaning the Data#The variable "mode" has two values for access points (mode = 3) and adhoc points (mode = 1). We will delete the adhoc points from the data set. This decreases the number of observations by about 100,000 rows.## name the variablesnames(offline) = c("time", "scanMac", "posX", "posY", "posZ", "orientation", "mac", "signal", "channel", "type")## Put the variables that should be numeric into a vectornumVars = c("time", "posX", "posY", "posZ", "orientation", "signal")## Change the mode of these variables to numericoffline[ numVars ] =  lapply(offline[ numVars ], as.numeric)offline = offline[ offline$type == "3", ] # Get rid of adhoc access pointsoffline = offline[ , "type" != names(offline) ] # No need for variable "type" now.dim(offline)#The next code chunk converts the time variables into POSIXt variables, which are time values in R.# POSIXt format in R uses the same origin (01/01/1970), but in secondsoffline$rawTime = offline$time # Keep raw time just in caseoffline$time = offline$time/1000 # Convert to secondsclass(offline$time) = c("POSIXt", "POSIXct") # Set class to date-times in Runlist(lapply(offline, class)) # Check the classes of all variables#When we check the class of the variables, we see the time variables are of class POSXIt or POSXIct, the numeric variables have the appropriate class, and the MAC addresses and channel are of class character. ## Question: the variable channel consists of a set of numbers. Why did we not change it to a numeric variable?#The code below computes summaries of the numeric variables and the character variables separately. For the numeric variables, summaries consist of the five-number summary and the mean. For character variables, the summary function produces a tally of the number of observations for each different category that the character variable undertakes. We also convert the character variables to factors in order to use them in data analysis.## Summariessummary(offline[, numVars])summary(sapply(offline[ , c("mac", "channel", "scanMac")],as.factor))#For the numeric variables, we see the times are within a month period from February to March of 2006. Measurements were taken at different times of the day. We also see that posZ has only one value, which is 0. This because all of the measurements were taken on one floor of a building, thus the third dimension of the position is 0 for all access points. The orientation of the user is as we expect, from 0 to 360 degrees. The signal stengths go from a minimum of -99 to a maximum of -25, with the mean at -61.7. The mean of the signal strength is fairly close to the median of -60, which may indicate that the signal strength has a symmetric distribution.#For the character variables, we see that scanMac has only one value, while there are many different mac addresses and many different channels. At this point, it is unclear what the categorization of "Other" indicates for these variables; therefore, we will need to investigate that category more closely.# Modify the data frame to eliminate scanMac and posZ. offline = offline[ , !(names(offline) %in% c("scanMac", "posZ"))]length(unique(offline$orientation))#According to the documentation, there should be eight distinct orientation values spaced 45 degrees apart. However, the result of the unique function tells us that there are 203 district values. We need to examine the data to see why this is the case. The EDF plot below is one way to examine the data. An empirical distribution function (EDF) is a plot of the cumulative proportion of values in a data set. For a discrete variable (like orientation), we would expect a step function with the location of each step representing the value of the orientation and the height of each step representing the additional proportion of the data corresponding to that value.plot(ecdf(offline$orientation), main="Figure 2", xlab="Degree of Orientation", ylab="Cumulative Proportion")#In Figure 2, the horizontal axis shows the degree of orientation from 0 to 360 degrees. The vertical axis is the cumulative proportion. The points on the line represent the orienation values. The line is drawn for display purposes and is not really necessary for the interpretation of the graph. #We see that most of the observations are at 45-degree intervals, as expected. Also, the relative proportions of these observations are the same, since the steps have equal height. However, some observations are to the right or left of the majority of the observations closest to them. For example, there is a set of observations at approximately 15 degrees and a set at approximately 320 degrees. Furthermore, there are a few observations close to 360 degrees, which probably should have been recorded as an orientation of 0 degrees. From this plot, we see that the 203 unique observations can be explained by the recording instrument being a little too exact. The users probably did not stand at *exactly* 45 or 90 or 180 degrees; however, their exact orientations were recorded.#The code below creats a nicer version of the EDF and a density plot, respecitively, and outputs them to PDF files in the current working directory. I have imported the density plot into this document.pdf(file = "Geo_ECDFOrientation.pdf", width = 10, height = 7)oldPar = par(mar = c(4, 4, 1, 1))plot(ecdf(offline$orientation), pch = 19, cex = 0.3,xlim = c(-5, 365), axes = FALSE,xlab = "orientation", ylab = "Empirical CDF", main = "")box()axis(2)axis(side = 1, at = seq(0, 360, by = 45))par(oldPar)dev.off()pdf(file = "Geo_DensityOrientation.pdf", width = 10, height = 5)oldPar = par(mar = c(4, 4, 1, 1))plot(density(offline$orientation, bw = 2), xlab = "orientation", main = "")par(oldPar)dev.off()# ![A density plot of the orientation angles. The x-axis indicates the value of the angle and the y-axis indicates the proportion of each angle. Each of the eight angles from the documentation are represented in roughly equal proportions, but there is some spread about each angle indicating round-off error.](Geo_DensityOrientation.pdf) #Since there is some spread around each orientation, we need to round the orientations to their reported values, and then examine the rounded data to make sure that we have the angles that the documentation calls for.roundOrientation = function(angles) {refs = seq(0, by = 45, length  = 9)q = sapply(angles, function(o) which.min(abs(o - refs)))c(refs[1:8], 0)[q]}offline$angle = roundOrientation(offline$orientation)with(offline, boxplot(orientation ~ angle, xlab = "Nearest 45 degree Angle",ylab="Orientation", main="Figure 3"))#Figure 3 shows a series of boxplots for each rounded angle. If the mapping had not worked, we would see spread (an actual box) at each of the points on the x-axis. As we see here, that is not the case. This plot confirms that the rounding function worked. The outliers in the upper left corner of the plot are those values near 360 degrees which were mapped to 0 degrees.#Next, we need to examine the MAC addresses for any behavior inconsistent with the documentation. This first piece of code counts the number of unique MAC addresses and the number of unique channels.c(length(unique(offline$mac)), length(unique(offline$channel)))table(offline$mac)#We see that there are 12 MAC addresses and 8 channels. The floor plan  led us to believe that there are only 6 access points. However, there are additional access points that were not a part of the testing area and were not on the floor plan. The table shows that there are three access points with very few readings assigned to them. Therefore, these were likely not part of the testing area. There are two other MAC addresses with small numbers of observations: the third and the fifth address. There is a large number of observations assigned to these, but not as large as the numbers assigned to the other addresses.#For the moment, we will keep the top seven MAC addresses. The code below locates those addresses and modifies the data set accordingly. Once we delete the access points with small numbers of observations, we have about 915K observations in the data set. Then, we confirm that the remaining MAC addresses have a one-to-one correspondance with the channels. This is indeed the case, which means that we can eliminate the channel variable from the data set. The channel variable is redundant.subMacs = names(sort(table(offline$mac), decreasing = TRUE))[1:7]offline = offline[ offline$mac %in% subMacs, ]dim(offline)macChannel = with(offline, table(mac, channel))apply(macChannel, 1, function(x) sum(x > 0))offline = offline[ , "channel" != names(offline)]#Now we need to examine the position variables, posX and posY. The by() function below gives us the number of unique combinations of x and y coordinates. We then store that information in a data frame called "locDF". The number of combinations is longer than the number of possible (x, y) coordinates. We also determine how many of these positions are empty. There are 310 empty positions. Since these combinations of x and y coordinates were not osberved, we delete them from the data frame. Now, we should have 166 locations from which signals were read.locDF = with(offline, by(offline, list(posX, posY), function(x) x))length(locDF)sum(sapply(locDF, is.null))locDF = locDF[ !sapply(locDF, is.null) ]length(locDF)#Next, we determine the number of observations recorded at each location. We see that there are approximately 5500 counts at each location. There is also code to create a graphic of the count and physical location of that count on the floor plan. locCounts = sapply(locDF, nrow)locCounts = sapply(locDF, function(df) c(df[1, c("posX", "posY")], count = nrow(df)))class(locCounts)dim(locCounts)locCounts[ , 1:8]#The function below reads in the data from the local directory and makes the changes made previously in this document. We have not analyzed the influence of the time variable. It is sometimes helpful to examine the order in which the entries were created in order to rule out potential sources of error and bias.## Function to read in the offline and online data and make necessary changes.readData = function(filename = 'Data/offline.final.trace.txt', subMacs = c("00:0f:a3:39:e1:c0", "00:0f:a3:39:dd:cd", "00:14:bf:b1:97:8a","00:14:bf:3b:c7:c6", "00:14:bf:b1:97:90", "00:14:bf:b1:97:8d","00:14:bf:b1:97:81")){  txt = readLines(filename)  lines = txt[ substr(txt, 1, 1) != "#" ]  tmp = lapply(lines, processLine)  offline = as.data.frame(do.call("rbind", tmp),   stringsAsFactors= FALSE)     names(offline) = c("time", "scanMac",   "posX", "posY", "posZ", "orientation",   "mac", "signal", "channel", "type")    # keep only signals from access points  offline = offline[ offline$type == "3", ]    # drop scanMac, posZ, channel, and type - no info in them  dropVars = c("scanMac", "posZ", "channel", "type")  offline = offline[ , !( names(offline) %in% dropVars ) ]    # drop more unwanted access points  offline = offline[ offline$mac %in% subMacs, ]    # convert numeric values  numVars = c("time", "posX", "posY", "orientation", "signal")  offline[ numVars ] = lapply(offline[ numVars ], as.numeric)    # convert time to POSIX  offline$rawTime = offline$time  offline$time = offline$time/1000  class(offline$time) = c("POSIXt", "POSIXct")    # round orientations to nearest 45  offline$angle = roundOrientation(offline$orientation)    return(offline)}pdf(file = "Geo_BoxplotSignalByMacAngle.pdf", width = 7)oldPar = par(mar = c(3.1, 3, 1, 1))offlineRedo = readData()identical(offline, offlineRedo)# Find global variables that are needed if we run this in a new R sessionlibrary(codetools)findGlobals(readData, merge=FALSE)$variables## Signal Strength Analysis# Boxplots of signal strength by position. Each panel is a different MAC address.library(lattice)bwplot(signal ~ factor(angle) | mac, data = offline, subset = posX == 2 & posY == 12 & mac != "00:0f:a3:39:dd:cd", layout = c(2,3))# par(oldPar)# dev.off()## Summary statistics for the signalsummary(offline$signal)## This code creates a PDF file. I commented out the part that creates the file so that it can be displayed in RStudio.# pdf(file = "Geo_DensitySignalByMacAngle.pdf", width = 8, height = 12)# oldPar = par(mar = c(3.1, 3, 1, 1))densityplot( ~ signal | mac + factor(angle), data = offline,subset = posX == 24 & posY == 4 & mac != "00:0f:a3:39:dd:cd",bw = 0.5, plot.points = FALSE)# par(oldPar)# dev.off() # You need this command to close the PDF file.## Eliminate a MAC address. This is commented out, so I didn't do it.# offline = offline[ offline$mac != "00:0f:a3:39:dd:cd", ]# posXY is afactor containing all unique combinations of (x,y) pairs at 166 locations.offline$posXY = paste(offline$posX, offline$posY, sep = "-")# Create a list of data frames for every combination of (x, y) angle and access point.byLocAngleAP = with(offline,                     by(offline, list(posXY, angle, mac),                        function(x) x))# Function to summarize signal data by AP, location and angle.signalSummary =   lapply(byLocAngleAP,                     function(oneLoc) {           ans = oneLoc[1, ]           ans$medSignal = median(oneLoc$signal)           ans$avgSignal = mean(oneLoc$signal)           ans$num = length(oneLoc$signal)           ans$sdSignal = sd(oneLoc$signal)           ans$iqrSignal = IQR(oneLoc$signal)           ans         })## Create a new data frame of the summary statisticsofflineSummary = do.call("rbind", signalSummary)     ## Plot of SD of signal by mean signal - parts that write the plot to a file are commented out.# pdf(file = "Geo_BoxplotSignalSDByAvg.pdf", width = 10)# oldPar = par(mar = c(3.1, 3, 1, 1))breaks = seq(-90, -30, by = 5)bwplot(sdSignal ~ cut(avgSignal, breaks = breaks),       data = offlineSummary,        subset = mac != "00:0f:a3:39:dd:cd",       xlab = "Mean Signal", ylab = "SD Signal")# par(oldPar)# dev.off()## Smoothed scatterplot of mean - median by location, angle, and AP versus the number of observations.## Darker blue indicates more observations. Most of the differences are close to 0.# pdf(file = "Geo_ScatterMean-Median.pdf", width = 10)# oldPar = par(mar = c(4.1, 4.1, 1, 1))with(offlineSummary,     smoothScatter((avgSignal - medSignal) ~ num,                   xlab = "Number of Observations",                    ylab = "mean - median"))abline(h = 0, col = "#984ea3", lwd = 2) #Add a horizontal line at 0.## Use LOESS to locally smooth the difference between mean and medianlo.obj =   with(offlineSummary,       loess(diff ~ num,              data = data.frame(diff = (avgSignal - medSignal),                               num = num)))# Plot the LOESS curve on the density plot.lo.obj.pr = predict(lo.obj, newdata = data.frame(num = (70:120)))lines(x = 70:120, y = lo.obj.pr, col = "#4daf4a", lwd = 2)# The LOESS curve is almost flat, indicating that there is little difference between the mean and median# par(oldPar)# dev.off()# The Relationship between Signal and Distance# Let's look at the relationship between signal and distance for one AP.oneAPAngle = subset(offlineSummary,                     mac == subMacs[5] & angle == 0)library(fields)smoothSS = Tps(oneAPAngle[, c("posX","posY")],                oneAPAngle$avgSignal)vizSmooth = predictSurface(smoothSS)plot.surface(vizSmooth, type = "C")points(oneAPAngle$posX, oneAPAngle$posY, pch=19, cex = 0.5)## surfaceSS is a function that allows use to get contour plots for specified APs and angles.surfaceSS = function(data, mac, angle = 45) {  require(fields)  oneAPAngle = data[ data$mac == mac & data$angle == angle, ]  smoothSS = Tps(oneAPAngle[, c("posX","posY")],                  oneAPAngle$avgSignal)  vizSmooth = predictSurface(smoothSS)  plot.surface(vizSmooth, type = "C",                xlab = "", ylab = "", xaxt = "n", yaxt = "n")  points(oneAPAngle$posX, oneAPAngle$posY, pch=19, cex = 0.5) }# parCur is an object containing plotting parameters for surfaceSS.## The parameters are set up to plot four plots on the same canvas.parCur = par(mfrow = c(2,2), mar = rep(1, 4))mapply(surfaceSS, mac = subMacs[ rep(c(5, 1), each = 2) ],        angle = rep(c(0, 135), 2),       data = list(data = offlineSummary))## The MAC address are returned. To which positions on the floor plan do they correspond?par(parCur)## We deleted the second MAC address because it looks just like the first.## In one of the case studies, you are asked to delete the first address, and then to delete neither, and see how the accuracy of the prediction changes.offlineSummary = subset(offlineSummary, mac != subMacs[2])# Relevant positions of access points on the floor planAP = matrix( c( 7.5, 6.3, 2.5, -.8, 12.8, -2.8,                  1, 14, 33.5, 9.3,  33.5, 2.8),             ncol = 2, byrow = TRUE,             dimnames = list(subMacs[ -2 ], c("x", "y") ))AP#The table gives the MAC addresses of the six access points that we have kept in the data frame. It also gives the x and y coordinate of each access point.#In the next code chunk, the goal is to obtain a scatterplot of the relationship between signal strength and the distance of each access point to the from the receiver. In order to do this, we first compute the differences, then we compute the Euclidean distance for each access plot. The resulting plot shows the relationship between signal and distance for each of 48 combinations of AP and angle.# Calculate Euclidean distancediffs = offlineSummary[ , c("posX", "posY")] -   AP[ offlineSummary$mac, ]offlineSummary$dist = sqrt(diffs[ , 1]^2 + diffs[ , 2]^2)xyplot(signal ~ dist | factor(mac) + factor(angle),        data = offlineSummary, pch = 19, cex = 0.3,       xlab ="distance")# The code below makes the plot pretty and writes it to a PDF file.pdf(file="Geo_ScatterSignalDist.pdf", width = 7, height = 10)oldPar = par(mar = c(3.1, 3.1, 1, 1))library(lattice)xyplot(signal ~ dist | factor(mac) + factor(angle),        data = offlineSummary, pch = 19, cex = 0.3,       xlab ="distance")par(oldPar)dev.off()## Nearest Neighbor Methods to Predict Locationmacs = unique(offlineSummary$mac)online = readData("Data/online.final.trace.txt", subMacs = macs)online$posXY = paste(online$posX, online$posY, sep = "-")length(unique(online$posXY))tabonlineXYA = table(online$posXY, online$angle)tabonlineXYA[1:6, ]keepVars = c("posXY", "posX","posY", "orientation", "angle")byLoc = with(online,              by(online, list(posXY),                 function(x) {                  ans = x[1, keepVars]                  avgSS = tapply(x$signal, x$mac, mean)                  y = matrix(avgSS, nrow = 1, ncol = 6,                             dimnames = list(ans$posXY, names(avgSS)))                  cbind(ans, y)                }))onlineSummary = do.call("rbind", byLoc)  dim(onlineSummary)names(onlineSummary)m = 3; angleNewObs = 230refs = seq(0, by = 45, length  = 8)nearestAngle = roundOrientation(angleNewObs)if (m %% 2 == 1) {  angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)} else {  m = m + 1  angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)  if (sign(angleNewObs - nearestAngle) > -1)     angles = angles[ -1 ]  else     angles = angles[ -m ]}angles = angles + nearestAngleangles[angles < 0] = angles[ angles < 0 ] + 360angles[angles > 360] = angles[ angles > 360 ] - 360offlineSubset =   offlineSummary[ offlineSummary$angle %in% angles, ]reshapeSS = function(data, varSignal = "signal",                      keepVars = c("posXY", "posX","posY")) {  byLocation =    with(data, by(data, list(posXY),                   function(x) {                    ans = x[1, keepVars]                    avgSS = tapply(x[ , varSignal ], x$mac, mean)                    y = matrix(avgSS, nrow = 1, ncol = 6,                               dimnames = list(ans$posXY,                                               names(avgSS)))                    cbind(ans, y)                  }))    newDataSS = do.call("rbind", byLocation)  return(newDataSS)}trainSS = reshapeSS(offlineSubset, varSignal = "avgSignal")selectTrain = function(angleNewObs, signals = NULL, m = 1){  # m is the number of angles to keep between 1 and 5  refs = seq(0, by = 45, length  = 8)  nearestAngle = roundOrientation(angleNewObs)    if (m %% 2 == 1)     angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)  else {    m = m + 1    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)    if (sign(angleNewObs - nearestAngle) > -1)       angles = angles[ -1 ]    else       angles = angles[ -m ]  }  angles = angles + nearestAngle  angles[angles < 0] = angles[ angles < 0 ] + 360  angles[angles > 360] = angles[ angles > 360 ] - 360  angles = sort(angles)     offlineSubset = signals[ signals$angle %in% angles, ]  reshapeSS(offlineSubset, varSignal = "avgSignal")}train130 = selectTrain(130, offlineSummary, m = 3)head(train130)length(train130[[1]])findNN = function(newSignal, trainSubset) {  diffs = apply(trainSubset[ , 4:9], 1,                 function(x) x - newSignal)  dists = apply(diffs, 2, function(x) sqrt(sum(x^2)) )  closest = order(dists)  return(trainSubset[closest, 1:3 ])}predXY = function(newSignals, newAngles, trainData,                   numAngles = 1, k = 3){    closeXY = list(length = nrow(newSignals))    for (i in 1:nrow(newSignals)) {    trainSS = selectTrain(newAngles[i], trainData, m = numAngles)    closeXY[[i]] =       findNN(newSignal = as.numeric(newSignals[i, ]), trainSS)  }    estXY = lapply(closeXY,                  function(x) sapply(x[ , 2:3],                                     function(x) mean(x[1:k])))  estXY = do.call("rbind", estXY)  return(estXY)}estXYk3 = predXY(newSignals = onlineSummary[ , 6:11],                  newAngles = onlineSummary[ , 4],                  offlineSummary, numAngles = 3, k = 3)estXYk1 = predXY(newSignals = onlineSummary[ , 6:11],                  newAngles = onlineSummary[ , 4],                  offlineSummary, numAngles = 3, k = 1)floorErrorMap = function(estXY, actualXY, trainPoints = NULL, AP = NULL){    plot(0, 0, xlim = c(0, 35), ylim = c(-3, 15), type = "n",       xlab = "", ylab = "", axes = FALSE)  box()  if ( !is.null(AP) ) points(AP, pch = 15)  if ( !is.null(trainPoints) )    points(trainPoints, pch = 19, col="grey", cex = 0.6)    points(x = actualXY[, 1], y = actualXY[, 2],          pch = 19, cex = 0.8 )  points(x = estXY[, 1], y = estXY[, 2],          pch = 8, cex = 0.8 )  segments(x0 = estXY[, 1], y0 = estXY[, 2],           x1 = actualXY[, 1], y1 = actualXY[ , 2],           lwd = 2, col = "red")}trainPoints = offlineSummary[ offlineSummary$angle == 0 &                                 offlineSummary$mac == "00:0f:a3:39:e1:c0" ,                              c("posX", "posY")]pdf(file="GEO_FloorPlanK3Errors.pdf", width = 10, height = 7)oldPar = par(mar = c(1, 1, 1, 1))floorErrorMap(estXYk3, onlineSummary[ , c("posX","posY")],               trainPoints = trainPoints, AP = AP)par(oldPar)dev.off()pdf(file="GEO_FloorPlanK1Errors.pdf", width = 10, height = 7)oldPar = par(mar = c(1, 1, 1, 1))floorErrorMap(estXYk1, onlineSummary[ , c("posX","posY")],               trainPoints = trainPoints, AP = AP)par(oldPar)dev.off()calcError =   function(estXY, actualXY)     sum( rowSums( (estXY - actualXY)^2) )actualXY = onlineSummary[ , c("posX", "posY")]sapply(list(estXYk1, estXYk3), calcError, actualXY)v = 11permuteLocs = sample(unique(offlineSummary$posXY))permuteLocs = matrix(permuteLocs, ncol = v,                      nrow = floor(length(permuteLocs)/v))onlineFold = subset(offlineSummary, posXY %in% permuteLocs[ , 1])reshapeSS = function(data, varSignal = "signal",                      keepVars = c("posXY", "posX","posY"),                     sampleAngle = FALSE,                      refs = seq(0, 315, by = 45)) {  byLocation =    with(data, by(data, list(posXY),                   function(x) {                    if (sampleAngle) {                      x = x[x$angle == sample(refs, size = 1), ]}                    ans = x[1, keepVars]                    avgSS = tapply(x[ , varSignal ], x$mac, mean)                    y = matrix(avgSS, nrow = 1, ncol = 6,                               dimnames = list(ans$posXY,                                               names(avgSS)))                    cbind(ans, y)                  }))    newDataSS = do.call("rbind", byLocation)  return(newDataSS)}offline = offline[ offline$mac != "00:0f:a3:39:dd:cd", ]keepVars = c("posXY", "posX","posY", "orientation", "angle")onlineCVSummary = reshapeSS(offline, keepVars = keepVars,                             sampleAngle = TRUE)onlineFold = subset(onlineCVSummary,                     posXY %in% permuteLocs[ , 1])offlineFold = subset(offlineSummary,                     posXY %in% permuteLocs[ , -1])estFold = predXY(newSignals = onlineFold[ , 6:11],                  newAngles = onlineFold[ , 4],                  offlineFold, numAngles = 3, k = 3)actualFold = onlineFold[ , c("posX", "posY")]calcError(estFold, actualFold)K = 20err = rep(0, K)for (j in 1:v) {  onlineFold = subset(onlineCVSummary,                       posXY %in% permuteLocs[ , j])  offlineFold = subset(offlineSummary,                       posXY %in% permuteLocs[ , -j])  actualFold = onlineFold[ , c("posX", "posY")]    for (k in 1:K) {    estFold = predXY(newSignals = onlineFold[ , 6:11],                     newAngles = onlineFold[ , 4],                      offlineFold, numAngles = 3, k = k)    err[k] = err[k] + calcError(estFold, actualFold)  }}pdf(file = "Geo_CVChoiceOfK.pdf", width = 10, height = 6)oldPar = par(mar = c(4, 3, 1, 1))plot(y = err, x = (1:K),  type = "l", lwd= 2,     ylim = c(1200, 2100),     xlab = "Number of Neighbors",     ylab = "Sum of Square Errors")rmseMin = min(err)kMin = which(err == rmseMin)[1]segments(x0 = 0, x1 = kMin, y0 = rmseMin, col = gray(0.4),          lty = 2, lwd = 2)segments(x0 = kMin, x1 = kMin, y0 = 1100,  y1 = rmseMin,          col = grey(0.4), lty = 2, lwd = 2)#mtext(kMin, side = 1, line = 1, at = kMin, col = grey(0.4))text(x = kMin - 2, y = rmseMin + 40,      label = as.character(round(rmseMin)), col = grey(0.4))par(oldPar)dev.off()estXYk5 = predXY(newSignals = onlineSummary[ , 6:11],                  newAngles = onlineSummary[ , 4],                  offlineSummary, numAngles = 3, k = 5)calcError(estXYk5, actualXY)predXY = function(newSignals, newAngles, trainData,                   numAngles = 1, k = 3){    closeXY = list(length = nrow(newSignals))    for (i in 1:nrow(newSignals)) {    trainSS = selectTrain(newAngles[i], trainData, m = numAngles)    closeXY[[i]] = findNN(newSignal = as.numeric(newSignals[i, ]),                          trainSS)  }    estXY = lapply(closeXY, function(x)    sapply(x[ , 2:3],            function(x) mean(x[1:k])))  estXY = do.call("rbind", estXY)  return(estXY)}