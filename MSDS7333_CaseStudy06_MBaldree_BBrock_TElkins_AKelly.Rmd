---
title: "MSDS 7333 Case Study 06"
author: "Matthew Baldree, Ben Brock, Tom Elkins, Austin Kelly"
date: "June 17, 2017"
output:
  html_notebook: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Table of Contents: {#TOC}
<li>[Assignment Requirements](#AssignmentOutline)</li>
<li>[Introduction](#Introduction)</li>
<li>[**Part 1**](#Part1)</li> 
<ul> 
  <li>[Signal Collection](#SigCol)</li>
  <li>[Signal Strength](#SigStren)</li>
  <li>[Signal Density](#SigDen)</li>
  <li>[Discussion](#Discussion)</li>
  <li>[k-Nearest Neighbors](#knn)</li>
</ul>
<li>[**Part 2**](#Part 2)</li>

<li>[References](#References)</li>
<li>[Appendix](#Appendix)</li>


<a id='AssignmentOutline'>

### <b>Assignment</b> </a>
1. Conduct a more thorough data analysis into these two MAC addresses, including determining locations by using data corresponding to both the *chosen* and *rejected* Access Points:
    + *Which of these two MAC addresses should be used and which should not be used for Real Time Location System (RTLS)?*
    + *Which MAC address yields the best prediction of location? (Including determining locations by using data corresponding to both MAC addresses)?*
    + *Does using data for both MAC addresses simultaneously yield more, or less accurate prediction of location?*

2. Implement alternative k-nearest prediction method using weights on received signal strength.
    + *For what range of values of weights are you able to obtain better prediction values than for the unweighted approach?*
    + *Use calcError() to compare approaches.*

[&uarr;TOC](#TOC)

***  

<a id='Introduction'>

### <b>Introduction</b></a>  
#### *Explain the case study*

<font color = "purple"><b>>>>>Everything in this color to be removed at final review<<<<</b></font>

<font color = "purple"><b>
- Discuss the goal of the case study
</b></font>

The case study in chapter 1 of the book Data Science in R by Nolan and Lang presented an indoor posiitoning system (IPS) for WiFi devices on a floor of a building at the University of Mannheim. The IPS was trained and tested with data collected at the University with a hand-held device on a grid of 166 points spaced one meter apart in the hallways. The algorithm for the IPS is the K-Nearest Neighbors (k-NN) [1]. 

The original investigators used a hand-held scanning device at each point and recorded a timestamp, mac id of the device, position of the device, the orientation of the device, and the following data for each WiFi access point (AP): recevied signal strength, channel frequency, and device mode of operation. The WiFi APs were located throughout the building and identified by their unique Media Access Control (MAC) address.

<font color = "red"><b>
- Need example training input line
- Need table of training data: name, description, type, example
</b></font>

<font color = "purple"><b>
- Discuss the different Access points and MAC Addresses
</b></font>

Six APs were initially discovered in the original anlysis in the case study. The authors then decided to reject AP "00:0f:a3:39:dd:cd" (rejectedAP) stating it was identified as an extra address. The details of their reasoning was not clearly explained. The authors chose AP "00:0f:a3:39:e1:c0" (chosenAP) instead. This case study will evalute the author's decision and decide if the IPS system would be more accurate with the chosenAP, rejectedAP, or both APs.

<font color = "purple"><b>
- BRIEF overview of K-Nearest Neighbors
</b></font>

k-NN algorithm is an ideal method because we have an abundant training data and our prediction is not based on parametric relationship with the data. It is based on proximity. The downside is the model must hold the entire training data set for maximum predictability. The k-NN model is trained on the training data and then tested on the test data to determine its accuracy. The number of neighbors to used for location prediction is adjusted to reduce the accuracy.

<font color = "red"><b>
- can we still a graphic from scikit-learn of k-NN model?
</b></font>

In part 1 of the case study, the author's original decision to rejected an AP is revisited to see if this was the best decision. In part 2, the prediction of X,Y based on the average of its neighbors is revisited and modified to a weighted sum of X,Y to determine if this change will produce better predictions. Alternate weights will alsobe analyzed.

***
# <a id='Part1'>Part 1: Access Point Analysis</a>  
Majority of the code in this case study was leveraged from [1]. The code was refactored for readibility and modified for part 1 and 2 analysis.

## 1.1 Read and Clean the Data

Set options parameters for printing and formatting.
```{r}
options(digits = 2)
options(error = recover, warn = 1)
```

Include helper functions defined in another notebook.
```{r}
source("MSDS7333-baldree-case6-fx.r", print.eval = TRUE)
```

Read in offline data used for training our model.
```{r}
offline = readData()
```

## 1.2 Analyze the Two Acess Points

Define the access point (AP) mac addresses that will be analyzed. We also define a variable for all remaining APs.

```{r}
chosenAP = "00:0f:a3:39:e1:c0"
rejectedAP = "00:0f:a3:39:dd:cd"
remainingAP = unique(offline[!offline$mac %in% c(chosenAP, rejectedAP),]$mac)
```

### 1.2.1 <a id='SigCol'>Signal Map</a>
Plot the total signals captured for each AP to determineif the coverage was similar. A severe gap in the number of points captured could be a reason for lower predictability.

The total signals for each AP mac in question, chosenAP and rejectedAP, are plotted at their respective X,Y point. We are unable to plot the access points (APs) directly on the map because we do not know their X, Y coordinates.

```{r}
plotSignalMaps(c(chosenAP, rejectedAP))
```

The maps show there were near equal amount of training points captured for both APs. A visual comparison of 
these two diagrams does not give us a significant insight into which MAC address should be kept and which should be rejected. Now, let us examine the distribution strength of the APs.

### 1.2.1 <a id='SigStren'> Signal Strength Distributions</a>
Plot the signal strength distributions for each AP per angle for better understanding at location (X=2, Y=12). A more thorough analysis would examine the distributions at all locations points, but time did not permit this in depth analysis. 

```{r}
df = subset(offline, posX ==2 & posY == 12 & !(mac %in% remainingAP), c(signal, angle, mac))
plotBoxplotSignalStrength(df)
```

The higher the decibel-milliwatts means a stronger signal strength which indicates a closer physical position to the AP since signal strengths decrease exponentially with distance.<font color="red">Find this in the book and cite it.</font> The distribution shows AP "e1:c0" has a stronger signal strength at this location than "dd:cd." But, the two of them together cover a wider range of signal coverage. What would this plot look like if we moved the fixed location point on the other side of the building at (X=33, Y=3)?
 
```{r}
# Let's focus on the fixed point (33,3)
df = subset(offline, posX == 33 & posY == 3 & !(mac %in% remainingAP), c(signal, angle, mac))
plotBoxplotSignalStrength(df)
```
This plot is similar to the previous distribution but with no outliers. At this point we know signal strength is different for the two access points. We don't know if this will effect our prediction accuracy. Now, let us analyzed the two APs signal strength distribution over angles.

### 1.2.2 <a id='SigDen'> Signal Density</a>
Plot signal strength frequency per capture angle for normalcy. 

```{r, fig.height=10}
df = subset(offline, posX == 24 & posY == 4 & !(mac %in% remainingAP), c(signal, angle, mac))
plotDensitySignalStrength(df)
```
The above plot, shows the rejectedAP "dd:cd" has a higher signal density at lower strength while the acceptedAP "e1:c0" has a higher density coverage at a higher strength. The distributions show that many of the plots are normally distributed while some of them; i.e., "dd:cd" at 180 and "e1:c0" at 315 are heavily skewed or even bimodal. Looking at each AP from top to bottom, there seems to exist an obvious pattern with respect to angle. This would suggest the median of each distribution varies by angle and attributes to a difference in perceived strength. This means the angle of the device contributes to the APs strength of signal.

#### Average Signal Strength Distributions
Plot the signal strengh distribution for all locations through the average signal strenth for all locations by angle. Summary statistics for all possible locations by angle was created. 

```{r}
offlineSummary = createOfflineSummary(offline)
```


```{r}
offline$posXY = paste(offline$posX, offline$posY, sep="-")

# create data frames for each combination
byLocAngleAP = with(offline, by(offline, list(posXY, angle, mac), function(x) x))
```

Now, we calculate the summary statistics:
```{r}
signalSummary = lapply(byLocAngleAP, function(oneLoc) {
  ans = oneLoc[1, ]
  ans$medSignal = median(oneLoc$signal)
  ans$avgSignal = mean(oneLoc$signal)
  ans$num = length(oneLoc$signal)
  ans$sdSignal = sd(oneLoc$signal)
  ans$iqrSignal = IQR(oneLoc$signal)
  ans
})
offlineSummary = do.call("rbind", signalSummary)
```

The Standard Deviation of the average signal strength per targeted AP:

```{r}
df = subset(offlineSummary, mac %in% c(chosenAP, rejectedAP), c(sdSignal, avgSignal, mac))
plotStdDevSignalStrength(df)
```

This above figure shows that there is considerable overlap between the two distributions of signal strength. This suggest that there may be value in keeping both APs in the k-NN model.

### 1.2.3 <a id='Discussion'>Discussion</a>
The data analysis shows that both APs are very similar except for the signal strength coverage. We do not have enough information at this time to determine if one AP is better or worse than the other. Therefore, we will examine each one in the k-NN model along with both of them to determine which option yields the best accuracy.

### 1.2.4 <a id='knn'>K-Nearest Neighbors</a>
k-NN is a non-parametric machine learning algorithm that is instance-based learning as opposed to generalize learning. Our first implementation of k-NN learns based on teh number of neighbors within signal strength distance to the point in question from the training points.[2] 

Print out the unique AP MAC addresses showing that we have six of them.
```{r}
macs = unique(offlineSummary$mac)
macs
```

Table the test data to review the frequency for each angle and each coordinate. 
```{r}
online = readData("online.final.trace.txt", subMacs = macs)
online$posXY = paste(online$posX, online$posY, sep = "-")
length(unique(online$posXY))
tabonlineXYA = table(online$posXY, online$angle)
#output shows measurements were taken at all angles throughout the floor
tabonlineXYA
```
The above output shows that each angle has test data meaning we can test all angle for accuracy.

Reshape the test data where each AP is in a column. 
```{r}
onlineSummary = castOnline(online)
#confirm rejected AP is included
dim(onlineSummary)
names(onlineSummary)
```

When it comes to the kNN, we need to include the data which include the angles close to the point in question. As observed before, angle matters. For this exercise, we need to abide by the following rules: 

  * If one angle is desired, then we will include angles which match the rounded orientation of the new observation  
  * If we want two angles, two multiples of 45 degrees will be chosen in order to encapsulate the nw observation's orientation  
  * For three angles, the nearest 45 degree increment is chosen and either side will be used.   

Now, we analyze or three scenarios for both APs included, rejectedAP left out, and then chosenAP left out. Three neighbors were used for three angles. The accuracy for each scenario as determined by the sum of squares difference between estimated XY and actual XY were outputted as well. Cross-validation was not used at this time.

```{r}
for (ap in c("None", rejectedAP, chosenAP)){
  if (ap == "None"){
    test = onlineSummary
    train = offlineSummary
    newSignals = test[ , 6:12]
  } else {
    test = onlineSummary[, !(names(onlineSummary) %in% ap)]
    train = subset(offlineSummary, mac != ap)
    newSignals = test[,6:11]
  }
  
  estXY = predXY(newSignals = newSignals,
                 newAngles = test[, 4],
                 train, 
                 numAngles = 3, k = 3)
  actXY = test[ , c("posX", "posY")]
  err = calcError(estXY, actXY)
  
  print(paste(ap, err))
}
```
The above results show that including both APs yielded a better prediction accuracy followed by keeping chosenAP and then rejectedAP. The author's choice to keep chosenAP was indeed better than rejectedAP, but keeping both of them is even better.

<font color = "Red">talk about cross-validation</font>

We will now perform cross-validation with both APs to determine the best k. Three angles will be used. Future work would include parameterization of the angles from 1 to 3 to determine to determine the best m. 

#### Cross-Validation
Choose a v-fold of 11.
```{r}
v = 11
```

```{r}
# number of locations
permuteLocs = sample(unique(offlineSummary$posXY))

```

```{r}
# matrix locations into folds
permuteLocs = matrix(permuteLocs, ncol = v, nrow = floor(length(permuteLocs)/v))
```

```{r}
# summarize and format offline
keepVars = c("posXY", "posX", "posY", "orientation", "angle")
onlineCVSummary = reshapeSS(offline, keepVars = keepVars, sampleAngle = TRUE)
```


```{r}
# number of k's
K = 10
# errors array
err = rep(0, K)

# loop through folds
for (j in 1:v) {
  testFold = subset(onlineCVSummary, posXY %in% permuteLocs[ , j])
  trainFold = subset(offlineSummary, posXY %in% permuteLocs[ , -j])
  actFold = testFold[ , c("posX", "posY")]

  # loop through neighbors
  for (k in 1:K) {
    estFold = predXY(newSignals = testFold[ , 6:12],
                     newAngles = testFold[ , 4],
                     trainFold, numAngles = 3, k = k)
    err[k] = err[k] + calcError(estFold, actFold)
  }
}
# plot k to sum of squared errors
plotSSErrors(err, K)
```
Given the plot above, the best k shows 9, but this changes if you rerun the cross-validation. Experimentation with k yielded 5 with the lowest error of 210 so it was used below.

```{r}
# experiment with a few k's based on above analysis to determine k
# that results in lowest sum squared error on test data.
estXY = predXY(newSignals = onlineSummary[ , 6:12],
               newAngles = onlineSummary[ , 4],
               offlineSummary, numAngles = 3, k = 5)
actXY = onlineSummary[ , c("posX", "posY")]
calcError(estXY, actXY)
```

<font color = "Red">provide some feel good about part 1. we concluded that keeping both APs yields better accuracy with a k-NN of 5 with 3 angles. We did not iterate of the angles to determine best parameter (arg!). The training data neighbors to the test data was determined by the signal strength distance and then the neighbors average X,Y was used to predict the test point location. </font>


# <a id='Part2'> Part 2: Alternative k-Nearest Neighbors</a>

## 2.1: Examination of Power-based search
The case study document mentioned the curvature in the scatterplots of signal strength versus distance, and suggested using a log function to attempt to remove the curve. Since the signal strength data are reported in dBm, they are already the result of a log function: $dBm = 10*log_{10}(power/1 mW)$; therefore, we converted the reported signal strength values back to a power value and examined the effect that had on location prediction.
Many of the functions used had to be modified to include the power conversion: $power = 10^{(signal/10)}$ and to use the new field in the calculations.
Examination of surface plots of power show that the power value tends to isolate the AP more definitively than signal strength because $power \propto 1/distance^2$.

![Contour plot of power for measurements against AP '97:8D' at 0 degrees orientation](contour1.png)
![Contour plot of power for measurements against AP 'E1:C0' at 0 degrees orientation](contour2.png)

The thought was that by having such a dramatic drop in power over a shorter range, we should be able to reduce the variability in predicted location and get better results.  However, when we simply substituted power for signal strength in the existing functions, the predictions using power were worse than using signal strength.
![Red lines indicate distance error between predicted location (*) and true location (black squares) using k=4](errors.png)

Using different values for 'k', we had these estimated errors:

| k |Mean distance error|Book-reported error|
|:-:|:-----------------:|:-----------------:|
| 1 |779.8603|659|
| 3 |598.8870|307|
| 4 |546.8603||
| 5 |640.8003|276|

Even though the power-based method better isolated the individual APs, we believe that the search algorithm should be redesigned to use all APs, instead of just one or two, due to the power drop-off.  As the distance from the reference AP increases, the power drops off so much that it becomes difficult to narrow down the actual location.  By redesigning the algorithm to use all APs, we may be able to capitalize on the power drop-off to better hone in on the target's location.


## 2.2: Weighted K-Nearest Neighbors

```{r}
# create weights for neighbors based on signal strength and multiple times X and Y and sum neighbors
# to get X and Y.
estXY = predXY(newSignals = onlineSummary[ , 6:12],
               newAngles = onlineSummary[ , 4],
               offlineSummary, numAngles = 3, k = 5, weighted=TRUE)
actXY = onlineSummary[ , c("posX", "posY")]
calcError(estXY, actXY)
```

***
# <a id='References'>References</a>
[1] Nolan, Deborah; Data Science in R; 2015; Predicting Location via Indoor Positioning Systems; Chapter 1. 
[2] Scikit-learn k-NN; http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbor-algorithms.

# <a id='Appendix'>Appendix (including function code)</a>
This is the code used to define the functions used within the study. It can be found under 'MSDS7333-baldree-case6-fx.r' which is included in the final submission. 
```{r eval=FALSE, echo=FALSE}
processLine = function(x)
{
  # Process a line of text returning a 11x10 matrix of tokens
  #
  # Args:
  #   x: The line of text
  #
  tokens = strsplit(x, "[;=,]")[[1]]

  # return NULL if only 10 tokens
  if (length(tokens) == 10)
    return(NULL)

  tmp = matrix(tokens[-(1:10)], ncol = 4, byrow = TRUE)
  mat = cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow(tmp), 6, byrow = TRUE), tmp)
}

roundOrientation = function(angles) {
  # Round an array of degree angles to the nearest 45 degree angle.
  #
  # Args:
  #   angles: The line of text
  #
  refs = seq(0, by = 45, length  = 9)
  q = sapply(angles, function(o) which.min(abs(o - refs)))
  c(refs[1:8], 0)[q]
}


readData = function(filename = 'offline.final.trace.txt',
                    subMacs = c("00:0f:a3:39:e1:c0", "00:0f:a3:39:dd:cd", "00:14:bf:b1:97:8a",
                                "00:14:bf:3b:c7:c6", "00:14:bf:b1:97:90", "00:14:bf:b1:97:8d",
                                "00:14:bf:b1:97:81")) {
  # Process the csv file peforming the following steps:
  #   Read all non-comment lines.
  #   Call processLine() for each line of text.
  #   Convert list of text into a data frame
  #   Name columns of data frame
  #   Define column types
  #   Convert millisecond time to seconds
  #   Round angle orientations
  #   Drop data
  #
  # Args:
  #   filename: The name of the csv file to process. The default is 'offline.final.trace.txt.'
  #   subMacs: The list of access point MAC addresses to filter the dataset down to. A default list is provided.
  #
  # Returns:
  #   The data frame
  #

  # process csv into matrix of tokens
  txt = readLines(filename)
  lines = txt[substr(txt, 1, 1) != "#"]
  tmp = lapply(lines, processLine)
  # convert into tokens into a data frame
  df = as.data.frame(do.call("rbind", tmp), stringsAsFactors = FALSE)

  # variable names
  names(df) = c("time", "scanMac", "posX", "posY", "posZ", "orientation", "mac", "signal", "channel", "type")

  # convert numeric values
  numVars = c("time", "posX", "posY", "orientation", "signal")
  df[numVars] = lapply(df[numVars], as.numeric)

  # convert time to POSIX
  df$rawTime = df$time
  df$time = df$time / 1000
  class(df$time) = c("POSIXt", "POSIXct")

  # round orientations to nearest 45
  df$angle = roundOrientation(df$orientation)

  # keep only signals from access points
  df = df[df$type == "3",]
  df = df[, "type" != names(df)]

  # drop scanMac, posZ, channel, and type - no info in them
  df = df[, !(names(df) %in% c("scanMac", "posZ"))]

  # drop more unwanted access points
  df = df[df$mac %in% subMacs,]

  # drop channel
  df = df[, "channel" != names(df)]

  return(df)
}

plotBoxplotSignalStrength = function(df) {
  # Box plot signal strength
  #
  # Args:
  #   df: data frame of data to analyze
  #
  oldPar = par(mar = c(3.1, 3.1, 1, 1), mfrow = c(1,1))
  par(mai=c(.8, .8, .5, .25))
  library (lattice)

  print(bwplot(signal ~ factor(angle) | mac, data = df, layout = c(2,1),
               main="Signal Strength Distribution for Access Points",
               xlab="Angle Measured (deg)", ylab="Signal Strengh (dBM)"))
  par(oldPar)
}

plotDensitySignalStrength = function(df) {
  # Density plot signal strength
  #
  # Args:
  #   df: data frame of data to analyze
  #
  oldPar = par(mar = c(3.1, 3.1, 1, 1), mfrow = c(1,1))
  par(mai=c(.8, .8, .5, .25))
  library (lattice)

  print(densityplot( ~ signal | mac + factor(angle), data = df, bw = 0.5, plot.points = FALSE,
        main="Signal Strength Distribution for Access Points",
        xlab="Angle Measured (deg)", ylab="Signal Strengh (dBM)"))
  par(oldPar)
}

plotStdDevSignalStrength = function(df) {
  # Standard Deviation of signal strength average
  #
  # Args:
  #   df: data frame of data to analyze
  #
  oldPar = par(mar = c(3.1, 3.1, 1, 1), mfrow = c(1,1))
  par(mai=c(.8, .8, .5, .25))
  library (lattice)
  breaks = seq(-90, -30, by=5)

  print(bwplot(sdSignal ~ cut(avgSignal, breaks=breaks) | mac, data=df,
               xlab = "Mean Signal (dBM)", ylab = "Signal Standard Deviation (dBM)",
               main = "Standard Deviation of Average Signal Strength from Detector to Access Point",
               cex.main=.8, cex.axis=.8, cex.lab=.8, layout = c(1, 2)))
  par(oldPar)
}


plotSignalMaps = function(macAddresses) {
  # Plot the number of signals per XY location at XY location.
  #
  # Args:
  #   macAddresses: a list of macs to plot signals
  #
  oldPar = par(mar = c(3.1, 3.1, 1, 1), mfrow = c(1,1))
  par(mfrow = c(2, 1), mai=c(.8, .8, .4, .25))

  for (i in macAddresses) {
    # filter data set
    df = offline[offline$mac %in% i, ]
    # location of datapoints filtered
    locDF = with(df, by(df, list(posX, posY), function(x) x))
    # drop locations that were not observed, null
    locDF = locDF[!sapply(locDF, is.null)]

    # determine the number of observations recorded at each location
    locCounts = sapply(locDF, nrow)

    # keep position information with location
    locCounts = sapply(locDF, function(df) c(df[1, c("posX", "posY")], count = nrow(df)))

    # transpose matrix
    locCounts = t(locCounts)
    plot(locCounts, type = "n", xlab = "Position X", ylab = "Position Y",
         main = paste("Total Signals from Detector to Access Point: ", i),
         cex.main=.8, cex.axis=.8, cex.lab=.8)
    text(locCounts, labels = locCounts[, 3], cex = .6, srt = 45)
  }
  par(oldPar)
}

castOnline = function(df) {
  # Cast dataframe of online data so each access point (AP) is in its own column.
  # Matrix is now a 1x7 since we are including rejected AP.
  #
  # Args:
  #   df: online data frame
  #
  keepVars = c("posXY", "posX","posY", "orientation", "angle")
  numOfAPs = length(unique(df$mac))
  byLoc = with(df,
               by(df, list(posXY),
                  function(x) {
                    ans = x[1, keepVars]
                    avgSS = tapply(x$signal, x$mac, mean)
                    y = matrix(avgSS, nrow = 1, ncol = numOfAPs,
                               dimnames = list(ans$posXY, names(avgSS)))
                    cbind(ans, y)
                  }))
  return(do.call("rbind", byLoc))
}

createOfflineSummary = function(df) {
  # In order to examine distribution for all locations, angles, and are two interested APs, we
  # will create a summary statistics for all location-orientation-AP combinations with a new factor.
  # For each combination there are around 100 observations.
  #
  # Args:
  #   df: offline data frame
  #
  df$posXY = paste(df$posX, df$posY, sep="-")

  # create data frames for each combination
  byLocAngleAP = with(df, by(df, list(posXY, angle, mac), function (x) x))

  # summary statistic
  signalSummary = lapply(byLocAngleAP, function(oneLoc) {
    ans = oneLoc[1, ]
    ans$medSignal = median(oneLoc$signal)
    ans$avgSignal = mean(oneLoc$signal)
    ans$num = length(oneLoc$signal)
    ans$sdSignal = sd(oneLoc$signal)
    ans$iqrSignal = IQR(oneLoc$signal)
    ans
  })
  return(do.call("rbind", signalSummary))
}

reshapeSS = function(df,
                     varSignal = "signal",
                     keepVars = c("posXY", "posX", "posY"),
                     sampleAngle = FALSE,
                     refs = seq(0, 315, by=45)) {
  # reshape signal strength help function
  # aggregate signal strengths from these angles and create a data structure similar to onlineSummary
  # Args:
  #   df: dataframe to reshape
  #   varSignal: variable to aggregate
  #   keepVars: variables to retain
  #   sampleAngle: true if we want to select one angle at random from df
  #   refs: angle references
  #
  numOfAPs = length(unique(df$mac))
  byLocation = with(df, by(df, list(posXY),
                             function(x) {
                               # select one angle at random for each location
                               if (sampleAngle) {
                                 x = x[x$angle == sample(refs, size = 1), ]}
                               ans = x[1, keepVars]
                               avgSS = tapply(x[, varSignal], x$mac, mean)
                               y = matrix(avgSS, nrow = 1, ncol = numOfAPs,
                                          dimnames = list(ans$posXY, names(avgSS)))
                               cbind(ans, y)
                             }))
  return(do.call("rbind", byLocation))
}

selectTraininingData = function(newObservationAngle, df = NULL, m = 1){
  # select observations from df to analyze aggregate signal strengths
  # from these angles and create a data structure similar to onlineSummary.
  #
  # Args:
  #   newObservationAngle: the angle of the new observation
  #   df: offline summary data frame
  #   m: number, between 1 and 5, of angles to keep

  # m is the number of angles to keep between 1 and 5
  refs = seq(0, by = 45, length  = 8)
  nearestAngle = roundOrientation(newObservationAngle)

  # handle odd and even m number
  if (m %% 2 == 1)
    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
  else {
    m = m + 1
    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
    if (sign(newObservationAngle - nearestAngle) > -1)
      angles = angles[ -1 ]
    else
      angles = angles[ -m ]
  }
  # map angles to values in refs
  # negative angles and angles greater than 360 are mapped to appropriate angles; e.g., -45 maps to 335 and 405 maps to 45
  angles = angles + nearestAngle
  angles[angles < 0] = angles[ angles < 0 ] + 360
  angles[angles > 360] = angles[ angles > 360 ] - 360
  angles = sort(angles)
  # select observations to analyze
  subset = df[df$angle %in% angles, ]
  # reshape signal strength
  return(reshapeSS(subset, varSignal = "avgSignal"))
}

findNN = function(newSignal, trainingSubset) {
  # want to look the distance in terms of signal strengths from these training data to the new
  # data point. we need to calculate teh distrance from the new point to all observations in the
  # training set with findNN().
  # returns locations of the training observations in order of closeness to the new observation's signal strength.
  #
  # Args:
  #   newSignal: signal of new observation
  #   trainingSubset: training data to find neighbors
  # Returns:
  #   training neighbors
  #
  cols = length(trainingSubset)
  diffs = apply(trainingSubset[ , 4:cols], 1, function(x) x - newSignal)
  dists = apply(diffs, 2, function(x) sqrt(sum(x^2)) )
  #closest = order(dists)
  closest = cbind(trainingSubset[, 1:3 ], dists)
  return(closest[order(dists),])
  #return(trainingSubset[closest, 1:3 ])
}

predXY = function(newSignals, newAngles, training, numAngles = 1, k = 3, weighted=FALSE){
  # Predict the XY coordinates given a list of signals along with their angles measured and training data.
  # k neighbors will be found to make the prediction of coordinate.
  #
  # Args:
  #   newSignals: list of signals to predict
  #   newAngles: list of angles for signals to predict
  #   trainingData: data needed for k-nn
  #   numAngles: angles we want to use for prediction
  #   k: number of neighbors to use for prediction
  #   weighted: if TRUE, distances to neighbors will be used to weight XY for each neighbor to determine
  #             location.
  #
  closeXY = list(length = nrow(newSignals))

  for (i in 1:nrow(newSignals)) {
    trainSS = selectTraininingData(newAngles[i], training, m = numAngles)
    closeXY[[i]] = findNN(newSignal = as.numeric(newSignals[i, ]), trainSS)
  }
  # for some k of nearest neighbors, simply average the first k locations
  # could have used weights in the average that are inversely proportional to the distance in signal strength
  # from the test observation. will need to call findNN() to get distance to point. the weights
  # are 1/d / sum(1/d).
  # could also use a different metric besides Euclidean like Manhattan.
  # could use medians instead of averages when combining neighbors if the distribution of values are quite skewed.
  if (!weighted) {
    estXY = lapply(closeXY, function(x) sapply(x[ , 2:3], function(x) mean(x[1:k])))
  } else {
    # sum X and Y weighted neighbor values.
    estXY = lapply(closeXY, function(x) {
      wt = (1/x[1:k, 4])/sum(1/x[1:k, 4])
      xy = cbind(x[1:k,], wt)
      # sum weighted neighbors
      return(colSums(xy[1:4, 2:3] * xy[1:4, 4]))
    })
  }
  return(do.call("rbind", estXY))
}

calcError = function(estXY, actualXY) {
  # compare fit numerically with sum of squared errors
  #
  # Args:
  #   estXY:
  #   actualXY:
  # Returns:
  #   calculated residual sum of squares
  return(sum(rowSums((estXY - actualXY) ^ 2)))
}

plotSSErrors = function(err, K){
  # Plot results as sum of squared errors as function of k
  #
  # Args:
  #   err: Error array
  #   K: number of neighbors
  #

  oldPar = par(mar = c(3.1, 3.1, 1, 1), mfrow = c(1,1))
  par(mai=c(.8, .8, .4, .25))

  plot(y = err, x = (1:K),  type = "l", lwd= 2, ylim = c(900, 2100), cex.main=.8, cex.axis=.8, cex.lab=.8,
       xlab = "Number of Neighbors",
       ylab = "Sum of Squared Errors",
       main = "Cross Validation Section of k")

  rmseMin = min(err)
  kMin = which(err == rmseMin)[1]
  segments(x0 = 0, x1 = kMin, y0 = rmseMin, col = gray(0.4), lty = 2, lwd = 2)
  segments(x0 = kMin, x1 = kMin, y0 = 800,  y1 = rmseMin, col = grey(0.4), lty = 2, lwd = 2)
  text(x = kMin - 2, y = rmseMin + 40, label = as.character(round(rmseMin)), col = grey(0.4), cex = .6)

  par(oldPar)
}

wt_signals <- function(ByAvgSig){
  
  # Name: wt_signals
  # Create weighted data
  #
  # Args:
  #   ByAvgSig:    estimate XY line segment
  #   
  # Returns:
  #   log_ang by weighted_signals matrix
  
  # calculate signals
  signals <- select(ByAvgSig, -posXY, -posX, -posY, -angle) 
  
  # calculate log_ang
  loc_ang <- select(ByAvgSig, posXY, posX, posY, angle)
  
  # calculate weighted_signals 
  weighted_signals <- (1/signals) / rowSums(1/signals)
  
  return(cbind(loc_ang, weighted_signals))
}
```
