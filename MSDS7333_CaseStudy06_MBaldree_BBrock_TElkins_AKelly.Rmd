---
title: "MSDS 7333 Case Study 06"
author: "Matthew Baldree, Ben Brock, Tom Elkins, Austin Kelly"
date: "June 17, 2017"
output:
  html_notebook: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Table of Contents: {#TOC}
<li>[Assignment Requirements](#AssignmentOutline)</li>
<li>[Introduction](#Introduction)</li>
<li>[**Part 1**](#Part1)</li>
<ul> 
  <li>[Signal Collection](#SigCol)</li>
  <li>[Signal Strength](#SigStren)</li>
  <li>[Signal Density](#SigDen)</li>
  <li>[Discussion](#Discussion)</li>
  <li>[k-Nearest Neighbors](#knn)</li>
</ul>
<li>[**Part 2**](#Part2)</li>
<ul> 
  <li>[2.1 Examining Power](#ExamPower)</li>
  <li>[2.2 Examining Weights](#ExamWeight)</li>
  <li>[2.3 Weighted kNN](#WtKNN)</li>
</ul>
<li>[References](#References)</li>
<li>[Appendix](#Appendix)</li>

<a id='AssignmentOutline'>

### <b>Assignment</b> </a>
1. Conduct a more thorough data analysis into these two MAC addresses, including determining locations by using data corresponding to both the *chosen* and *rejected* Access Points:
    + *Which of these two MAC addresses should be used and which should not be used for Real Time Location System (RTLS)?*
    + *Which MAC address yields the best prediction of location? (Including determining locations by using data corresponding to both MAC addresses)?*
    + *Does using data for both MAC addresses simultaneously yield more, or less accurate prediction of location?*

2. Implement alternative k-nearest neighbors prediction method using weights on received signal strength.
    + *For what range of values of weights are you able to obtain better prediction values than for the unweighted approach?*
    + *Use calcError() to compare approaches.*

[&uarr;TOC](#TOC)

***  

<a id='Introduction'>

### <b>Introduction</b></a>  
#### *Explain the case study*

<font color = "purple"><b>>>>>Everything in this color to be removed at final review<<<<</b></font>

<font color = "purple"><b>
- Discuss the goal of the case study
</b></font>

The case study in chapter 1 of the book *Data Science in R* by Nolan and Lang presented an indoor posiitoning system (IPS) for WiFi devices on a floor of a building at the University of Mannheim. The IPS was trained and tested with data collected at the University with a hand-held device on a grid of 166 points spaced one meter apart in the hallways. The algorithm for the IPS is the K-Nearest Neighbors (k-NN) [1](#REF01). 

The original investigators used a hand-held scanning device at each point and recorded a timestamp, MAC id of the device, position of the device, the orientation of the device, and the following data for each WiFi access point (AP): recevied signal strength, channel frequency, and device mode of operation. The WiFi APs were located throughout the building and identified by their unique Media Access Control (MAC) address.

<font color = "red"><b>
- Need example training input line

t=1139643118358;id=00:02:2D:21:0F:33;pos=0.0,0.0,0.0;degree=0.0;00:14:bf:b1:97:8a=-38,2437000000,3;00:14:bf:b1:97:90=-56,2427000000,3;00:0f:a3:39:e1:c0=-53,2462000000,3;00:14:bf:b1:97:8d=-65,2442000000,3;00:14:bf:b1:97:81=-65,2422000000,3;00:14:bf:3b:c7:c6=-66,2432000000,3;00:0f:a3:39:dd:cd=-75,2412000000,3;00:0f:a3:39:e0:4b=-78,2462000000,3;00:0f:a3:39:e2:10=-87,2437000000,3;02:64:fb:68:52:e6=-88,2447000000,1;02:00:42:55:31:00=-84,2457000000,1


- Need table of training data: name, description, type, example

|Data Element|Description|Type|Example|
|:-|:-|:-|:-|
|t |timestamp (milliseconds since midnight 1/1/1970)|long integer|t=1139643118358 --> 2/11/2006 07:35:28|
|id|target device MAC address|6-octet sequence in hexadecimal|id=00:02:2D:21:0F:33|
|pos|coordinates of the target device in meters from a choke point in the host building|3 floating point values, comma-separated|pos=0.0,0.0,0.0|
|degree|Orientation of the target device (with respect to North) in degrees|float|degree=0.0|
|MAC Address|one or more reports from various Access Points|comma-separated value list|00:14:bf:b1:97:8a=-38,2437000000,3|

|Data Element|Description|Type|Example|
|-|-|-|-|
|signal|The signal strength reported for the Access Point in dBm|integer|-38|
|channel|The frequency of the channel used by the Access Point in Hz|integer|2437000000|
|mode|The mode of operation for the Access Point (1 = Ad Hoc, 3 = Access Point)|integer|3|

</b></font>

<font color = "purple"><b>
- Discuss the different Access points and MAC Addresses
</b></font>

Six APs were initially discovered in the original analysis in the case study. The authors then decided to reject AP "00:0f:a3:39:dd:cd" (rejectedAP) stating it was identified as an extra address. The details of their reasoning was not clearly explained. The authors chose AP "00:0f:a3:39:e1:c0" (chosenAP) instead. This case study will evalute the author's decision and decide if the IPS system would be more accurate with the chosenAP, rejectedAP, or both APs.

<font color = "purple"><b>
- BRIEF overview of K-Nearest Neighbors
</b></font>

The k-NN algorithm is an ideal method because we have an abundant training data set and our prediction is not based on parametric relationship with the data. It is based on proximity. The downside is the model must hold the entire training data set in memory for maximum predictability. The k-NN model is trained on the training data and then tested on the test data to determine its accuracy. The number of neighbors to be used for location prediction is adjusted to improve the accuracy.

<font color = "red"><b>
- can we still a graphic from scikit-learn of k-NN model?
</b></font>

In part 1 of the case study, the author's original decision to reject an AP is revisited to see if this was the best decision. In part 2, the prediction of X,Y based on the average of its neighbors is revisited and modified to a weighted sum of X,Y to determine if this change will produce better predictions. Alternate weights will also be analyzed.

[&uarr;TOC](#TOC)

***
# <a id='Part1'>Part 1: Access Point Analysis</a>  

The majority of the code in this case study was leveraged from [1](#Ref01). The code was refactored for readibility and modified for part 1 and 2 analysis.

## 1.1 Read and Clean the Data

Set options parameters for printing and formatting.
```{r}
options(digits = 2)
options(error = recover, warn = 1)
```

Include helper functions defined in another notebook.
```{r}
source("MSDS7333-baldree-case6-fx.r", print.eval = TRUE)
```

Read in offline data used for training our model.
```{r}
offline = readData()
```

## 1.2 Analyze the Two Acess Points

Define the access point (AP) MAC addresses that will be analyzed. We also define a variable for all remaining APs.

```{r}
chosenAP = "00:0f:a3:39:e1:c0"
rejectedAP = "00:0f:a3:39:dd:cd"
remainingAP = unique(offline[!offline$mac %in% c(chosenAP, rejectedAP),]$mac)
```
[&uarr;TOC](#TOC)


### 1.2.1 <a id='SigCol'>Signal Map</a>
Plot the total signals captured for each AP to determine if the coverage was similar. A severe gap in the number of points captured could be a reason for lower predictability.

The total signals for each AP MAC in question, chosenAP and rejectedAP, are plotted at their respective X,Y point. We are unable to plot the access points (APs) directly on the map because we do not know their X, Y coordinates.

```{r}
plotSignalMaps(c(chosenAP, rejectedAP))
#  figure 1 - number of reports at each location for the rejected and chosen APs.
```

The maps show there were near equal amounts of training points captured for both APs. A visual comparison of 
these two diagrams does not give us sufficient insight into which MAC address should be kept and which should be rejected. Now, let us examine the distribution strength of the APs.

[&uarr;TOC](#TOC)


### 1.2.1 <a id='SigStren'> Signal Strength Distributions</a>
Plot the signal strength distributions for each AP per angle for better understanding at location (X=2, Y=12). A more thorough analysis would examine the distributions at all locations points, but time did not permit this in-depth analysis. 

```{r}
df = subset(offline, posX ==2 & posY == 12 & !(mac %in% remainingAP), c(signal, angle, mac))
plotBoxplotSignalStrength(df)
# figure 2 - Signal strength distribution across both Access Points
```

The higher the decibel-milliwatts means a stronger signal strength which indicates a closer physical position to the AP since signal strength decreases exponentially with distance.<font color="red">Find this in the book and cite it.</font> The distribution shows AP "e1:c0" has a stronger signal strength at this location than "dd:cd." But, the two of them together cover a wider range of signal coverage. What would this plot look like if we moved the fixed location point on the other side of the building at (X=33, Y=3)?
 
```{r}
# Let's focus on the fixed point (33,3)
df = subset(offline, posX == 33 & posY == 3 & !(mac %in% remainingAP), c(signal, angle, mac))
plotBoxplotSignalStrength(df)
# figure 3 - Signal strength distribution for a point at the other end of the building
```
This plot is similar to the previous distribution but with no outliers. At this point we know signal strength is different for the two access points. We don't know if this will affect our prediction accuracy. Now, let us analyze the two AP's signal strength distribution over angles.

[&uarr;TOC](#TOC)


### 1.2.2 <a id='SigDen'> Signal Density</a>
Plot signal strength frequency per capture angle for normalcy. 

```{r, fig.height=10}
df = subset(offline, posX == 24 & posY == 4 & !(mac %in% remainingAP), c(signal, angle, mac))
plotDensitySignalStrength(df)
# figure 4 - Signal strength distribution across angles
```
The above plot, shows the rejectedAP "dd:cd" has a higher signal density at lower strength while the acceptedAP "e1:c0" has a higher density coverage at a higher strength. The distributions show that many of the plots are normally distributed while some of them; i.e., "dd:cd" at 180 and "e1:c0" at 315 are heavily skewed or even bimodal. Looking at each AP from top to bottom, there seems to exist an obvious pattern with respect to angle. This would suggest the median of each distribution varies by angle which can be attributed to a difference in perceived strength. This means the angle of the device contributes to the APs strength of signal.

#### Average Signal Strength Distributions
Plot the signal strength distribution for all locations through the average signal strength for all locations by angle. Summary statistics for all possible locations by angle was created. 

```{r}
offlineSummary = createOfflineSummary(offline)
```


```{r}
offline$posXY = paste(offline$posX, offline$posY, sep="-")

# create data frames for each combination
byLocAngleAP = with(offline, by(offline, list(posXY, angle, mac), function(x) x))
```

Now, we calculate the summary statistics:
```{r}
signalSummary = lapply(byLocAngleAP, function(oneLoc) {
  ans = oneLoc[1, ]
  ans$medSignal = median(oneLoc$signal)
  ans$avgSignal = mean(oneLoc$signal)
  ans$num = length(oneLoc$signal)
  ans$sdSignal = sd(oneLoc$signal)
  ans$iqrSignal = IQR(oneLoc$signal)
  ans
})
offlineSummary = do.call("rbind", signalSummary)
```

The Standard Deviation of the average signal strength per targeted AP:

```{r}
df = subset(offlineSummary, mac %in% c(chosenAP, rejectedAP), c(sdSignal, avgSignal, mac))
plotStdDevSignalStrength(df)
# figure 5 - Standard deviation of average signal strength
```

This above figure shows that there is considerable overlap between the two distributions of signal strength. This suggest that there may be value in keeping both APs in the k-NN model.

[&uarr;TOC](#TOC)

### 1.2.3 <a id='Discussion'>Discussion</a>
The data analysis shows that both APs are very similar except for the signal strength coverage. We do not have enough information at this time to determine if one AP is better or worse than the other. Therefore, we will examine each one in the k-NN model along with both of them to determine which option yields the best accuracy.

[&uarr;TOC](#TOC)

### 1.2.4 <a id='knn'>K-Nearest Neighbors</a>
k-NN is a non-parametric machine learning algorithm that is instance-based learning as opposed to generalized learning. Our first implementation of k-NN learns based on the number of neighbors within signal strength distance to the point in question from the training points.[2](#Ref02) 

Print out the unique AP MAC addresses showing that we have six of them.
```{r}
macs = unique(offlineSummary$mac)
macs
# Table 3 - Unique Access Points
```

Table the test data to review the frequency for each angle and each coordinate. 
```{r}
online = readData("online.final.trace.txt", subMacs = macs)
online$posXY = paste(online$posX, online$posY, sep = "-")
length(unique(online$posXY))
tabonlineXYA = table(online$posXY, online$angle)
#output shows measurements were taken at all angles throughout the floor
tabonlineXYA
# Table 5 - Test data counts per location and angle
```
The above output shows that each angle has test data meaning we can test all angle for accuracy.

Reshape the test data where each AP is in a column. 
```{r}
onlineSummary = castOnline(online)
#confirm rejected AP is included
dim(onlineSummary)
names(onlineSummary)
# Table 6 - Reshaped test data set
```

When it comes to the kNN, we need to include the data which include the angles close to the point in question. As observed before, angle matters. For this exercise, we need to abide by the following rules: 

  * If one angle is desired, then we will include angles which match the rounded orientation of the new observation  
  * If we want two angles, two multiples of 45 degrees will be chosen in order to encapsulate the new observation's orientation  
  * For three angles, the nearest 45 degree increment is chosen and either side will be used.   

Now, we analyze our three scenarios for both APs included, rejectedAP left out, and then chosenAP left out. Three neighbors were used for three angles. The accuracy for each scenario as determined by the sum of squares difference between estimated X,Y and actual X,Y were output as well. Cross-validation was not used at this time.

```{r}
for (ap in c("None", rejectedAP, chosenAP)){
  if (ap == "None"){
    test = onlineSummary
    train = offlineSummary
    newSignals = test[ , 6:12]
  } else {
    test = onlineSummary[, !(names(onlineSummary) %in% ap)]
    train = subset(offlineSummary, mac != ap)
    newSignals = test[,6:11]
  }
  
  estXY = predXY(newSignals = newSignals,
                 newAngles = test[, 4],
                 train, 
                 numAngles = 3, k = 3)
  actXY = test[ , c("posX", "posY")]
  err = calcError(estXY, actXY)
  
  print(paste(ap, err))
}
# Table 7 - Accuracies for the various scenarios
```
The above results show that including both APs yielded a better prediction accuracy followed by keeping chosenAP and then rejectedAP. The author's choice to keep chosenAP was indeed better than rejectedAP, but keeping both of them is even better.

<font color = "Red">talk about cross-validation</font>

We next performed cross-validation with both APs to determine the best k. Three angles were used. Future work would include parameterization of the angles from 1 to 3 to determine the best m. 

#### Cross-Validation
Choose a v-fold of 11.
```{r}
v = 11
```

```{r}
# number of locations
permuteLocs = sample(unique(offlineSummary$posXY))

```

```{r}
# matrix locations into folds
permuteLocs = matrix(permuteLocs, ncol = v, nrow = floor(length(permuteLocs)/v))
```

```{r}
# summarize and format offline
keepVars = c("posXY", "posX", "posY", "orientation", "angle")
onlineCVSummary = reshapeSS(offline, keepVars = keepVars, sampleAngle = TRUE)
```


```{r}
# number of k's
K = 10
# errors array
err = rep(0, K)

# loop through folds
for (j in 1:v) {
  testFold = subset(onlineCVSummary, posXY %in% permuteLocs[ , j])
  trainFold = subset(offlineSummary, posXY %in% permuteLocs[ , -j])
  actFold = testFold[ , c("posX", "posY")]

  # loop through neighbors
  for (k in 1:K) {
    estFold = predXY(newSignals = testFold[ , 6:12],
                     newAngles = testFold[ , 4],
                     trainFold, numAngles = 3, k = k)
    err[k] = err[k] + calcError(estFold, actFold)
  }
}
# plot k to sum of squared errors
plotSSErrors(err, K)
# figure 6 - estimated ideal 'k'
```
Given the plot above, the best k shows 9, but this changes if you rerun the cross-validation. Experimentation with k yielded 5 with the lowest error of 210 so it was used below.

```{r}
# experiment with a few k's based on above analysis to determine k
# that results in lowest sum squared error on test data.
estXY = predXY(newSignals = onlineSummary[ , 6:12],
               newAngles = onlineSummary[ , 4],
               offlineSummary, numAngles = 3, k = 5)
actXY = onlineSummary[ , c("posX", "posY")]
calcError(estXY, actXY)
```

<font color = "Red">provide some feel good about part 1. we concluded that keeping both APs yields better accuracy with a k-NN of 5 with 3 angles. We did not iterate of the angles to determine best parameter (arg!). The training data neighbors to the test data was determined by the signal strength distance and then the neighbors average X,Y was used to predict the test point location. </font>

[&uarr;TOC](#TOC)

# <a id='Part2'> Part 2: Alternative k-Nearest Neighbors</a>

## 2.1: Examination of Power-based search {#ExamPower}
The case study document mentioned the curvature in the scatterplots of signal strength versus distance, and suggested using a log function to attempt to remove the curve. Since the signal strength data are reported in dBm, they are already the result of a log function: $dBm = 10*log_{10}(power/1 mW)$; therefore, we converted the reported signal strength values back to a power value and examined the effect that had on location prediction.
Many of the functions used previously had to be modified to include the power conversion: $power = 10^{(signal/10)}$ and to use the new field in the calculations.
Examination of surface plots of power show that the power value tends to isolate the AP more definitively than signal strength because $power \propto 1/distance^2$.

![Figure 7 - Contour plot of power for measurements against AP '97:8D' at 0 degrees orientation](contour1.png)

![Figure 8 - Contour plot of power for measurements against AP 'E1:C0' at 0 degrees orientation](contour2.png)

The thought was that by having such a dramatic drop in power over a shorter range, we should be able to reduce the variability in predicted location and get better results.  However, when we simply substituted power for signal strength in the existing functions, the predictions using power were worse than using signal strength.

![Figure 9 - Red lines indicate distance error between predicted location (*) and true location (black squares) using k=4](errors.png)

Using different values for 'k', we had these estimated errors:

| k |Power-based error|Signal-strength-based error|
|:-:|:-----------------:|:-----------------:|
| 1 |779.8603|659|
| 3 |598.8870|307|
| 4 |546.8603||
| 5 |640.8003|276|

*Table 8 - Comparison of predicted location errors between power-based and signal-strength-based approaches*

Even though the power-based method better isolated the individual APs, we believe that the search algorithm should be redesigned to use all APs, instead of just one or two, due to the power drop-off.  As the distance from the reference AP increases, the power drops off so much that it becomes difficult to narrow down the actual location.  By redesigning the algorithm to use all APs, we may be able to capitalize on the power drop-off to better hone in on the target's location.

[&uarr;TOC](#TOC)

##2.2: Investigating Weights {#ExamWeight}

The description of the weighting procedure brought up some questions about the meaningfulness of the approach.  This led to a side investigation of how the nearest-neighbors method might be affected by weights.

The investigation involved exporting the offine summary dataset and the online dataset to CSV files for use in Excel.  Then we looked at the process manually - taking the first report in the online dataset that matched our reference AP and looking for nearest neighbors in the offline summary dataset.  The target record stated the true position to be 0, 0.05 (lower left corner of the building).  The reference AP is within line of sight of the target device at coordinates 1,14.

First, we selected only those records in the offline summary that matched the AP, then further filtered to those records that matched orientation (135 degrees).  Plotting the measured signal strength for that AP and orientation, we can see that there is a fairly extensive swath of positions in which the target signal strength can occur.  

![*Figure 10 - Signal strength from AP @ 1,14*](SignalStrength1.png)

Using the Excel function SMALL, we can find the k smallest differences - these would be the k nearest neighbors.

|Record#|Sig Str Diff|Pos X|Pos Y|
|:-----:|:----------:|:---:|:---:|
| 3767  | 0.0196078  | 4   | 7   |
|  357  | 0.0202128  | 1   | 2   |
|  117  | 0.3846154  | 2   | 0   |
| 3817  | 0.9354839  | 3   | 7   |
|  505  | 1.0510204  | 1   | 3   |

*Table 9 - Nearest neighbors for the target's signal strength*

Avg X = 2.2; Avg Y = 3.8; True X = 0.0; True Y = 0.05; Error = 4.3477

We can see that the target's reported signal strength occurs throughout the corridor as shown in the signal strength plot above.  Averaging those values pulls the estimate away from the true area.

If we consider weighting the neighbors based on physical distance (as was suggested in the case study), the points closer to the AP will be weighted higher than the points further away, which would (in this particular example) pull the estimated location further away from the true location and closer to the AP, increasing the error further.

The case study also hints at using multiple APs to do the neighbor selection.  If, for example, we chose the AP at the opposite corner of the building (the lower right corner), and examined the same target report as before, we can see an additional problem: 

![*Figure 11 - Signal strength from AP @ 33.5,2.8*](SignalStrength2.png)

Now if we look for just simple differences in signal strength, we can get points for either AP that could be spread across the entire building.

|Record#|Sig Str Diff|Pos X|Pos Y|AP|
|:-----:|:----------:|:---:|:---:|:-:|
|  670  | 0.0625     | 4   | 3   |1, 14|
|  2568 | 0.0919540  | 15  | 8   |33.5, 2.8|
|  856  | 0.1034483  | 11  | 4   |33.5, 2.8|
|  936  | 0.1263158  | 12  | 5   |33.5, 2.8|
|  408  | 0.1612903  | 0   | 7   |1, 14|

*Table 10 - Nearest neighbors for the target's signal strength across two APs*

Avg X = 8.4; Avg Y = 5.4; True X = 0.0; True Y = 0.05; Error = 9.959

Again, weighting the neighbors on physical distance reinforces a location closer to the AP at 33.5, 2.8, which increases the error from the true location.

One possible approach is to use the simultaneous measurements as a group and find nearest neighbors that exhibit similar patterns.  For example the test record we have used here is part of a series of measurements taken at the same time and orientation.  The highest average signal strength was against AP 97:8A (-43.25 dBm) and the lowest average signal strength was against AP 97:8D (-63 dBm). If we search for that pattern in the training data, we get a more reasonable set of neighbors:

|Timestamp|97:8A signal|97:8D signal|Signal "Dist"|Pos X|Pos Y|
|:-------:|:----------:|:----------:|:-----------:|:---:|:---:|
|02:45:43 | -43 | -63 | 0.25  |1 | 5 |
|02:14:34 | -44 | -63 | 0.75  |1 | 4 |
|01:06:28 | -44 | -61 | 2.136 |0 | 1 |
|06:31:15 | -41 | -63 | 2.25  |2 | 12|
|00:35:27 | -41 | -64 | 2.462 |0 | 0 |

*Table 11 - Nearest neighbors for the target's strongest and weakest signal strength*

Avg X = 0.8; Avg Y = 4.4; True X = 0.0; True Y = 0.05; Error = 4.423

Future work into this approach with appropriate weighting could prove to reduce location prediction errors.

[&uarr;TOC](#TOC)

## 2.3: Weighted K-Nearest Neighbors {#WtKNN}

Prediction based on weighted X and Y &darr;

```{r}
estXY = predXY(newSignals = onlineSummary[ , 6:12],
               newAngles = onlineSummary[, 4],
               offlineSummary, numAngles = 3, k = 5, weighted = TRUE, exp = .5)
actXY = onlineSummary[, c("posX","posY")]
calcError(estXY, actXY)
```

&darr; this is equivalent to mean SS error result of 210

```{r}
estXY = predXY(newSignals = onlineSummary[ , 6:12],
               newAngles = onlineSummary[, 4],
               offlineSummary, numAngles = 3, k = 5, weighted = TRUE, exp = .001)
actXY = onlineSummary[, c("posX","posY")]
calcError(estXY, actXY)
```

[&uarr;TOC](#TOC)

***
# <a id='References'>References</a>
* <a href='REF01'></a> [1] Nolan, Deborah; Data Science in R; 2015; Predicting Location via Indoor Positioning Systems; Chapter 1. 

* <a href='REF02'></a> [2] Scikit-learn k-NN; http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbor-algorithms. 

# <a id='Appendix'>Appendix (including function code)</a>
This is the code used to define the functions used within the study. It can be found under 'MSDS7333-baldree-case6-fx.r' which is included in the final submission. 
```{r eval=FALSE, echo=FALSE}
processLine = function(x)
{
  # Process a line of text returning a 11x10 matrix of tokens
  #
  # Args:
  #   x: The line of text
  #
  tokens = strsplit(x, "[;=,]")[[1]]

  # return NULL if only 10 tokens
  if (length(tokens) == 10)
    return(NULL)

  tmp = matrix(tokens[-(1:10)], ncol = 4, byrow = TRUE)
  mat = cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow(tmp), 6, byrow = TRUE), tmp)
}

roundOrientation = function(angles) {
  # Round an array of degree angles to the nearest 45 degree angle.
  #
  # Args:
  #   angles: The line of text
  #
  refs = seq(0, by = 45, length  = 9)
  q = sapply(angles, function(o) which.min(abs(o - refs)))
  c(refs[1:8], 0)[q]
}


readData = function(filename = 'offline.final.trace.txt',
                    subMacs = c("00:0f:a3:39:e1:c0", "00:0f:a3:39:dd:cd", "00:14:bf:b1:97:8a",
                                "00:14:bf:3b:c7:c6", "00:14:bf:b1:97:90", "00:14:bf:b1:97:8d",
                                "00:14:bf:b1:97:81")) {
  # Process the csv file peforming the following steps:
  #   Read all non-comment lines.
  #   Call processLine() for each line of text.
  #   Convert list of text into a data frame
  #   Name columns of data frame
  #   Define column types
  #   Convert millisecond time to seconds
  #   Round angle orientations
  #   Drop data
  #
  # Args:
  #   filename: The name of the csv file to process. The default is 'offline.final.trace.txt.'
  #   subMacs: The list of access point MAC addresses to filter the dataset down to. A default list is provided.
  #
  # Returns:
  #   The data frame
  #

  # process csv into matrix of tokens
  txt = readLines(filename)
  lines = txt[substr(txt, 1, 1) != "#"]
  tmp = lapply(lines, processLine)
  # convert into tokens into a data frame
  df = as.data.frame(do.call("rbind", tmp), stringsAsFactors = FALSE)

  # variable names
  names(df) = c("time", "scanMac", "posX", "posY", "posZ", "orientation", "mac", "signal", "channel", "type")

  # convert numeric values
  numVars = c("time", "posX", "posY", "orientation", "signal")
  df[numVars] = lapply(df[numVars], as.numeric)

  # convert time to POSIX
  df$rawTime = df$time
  df$time = df$time / 1000
  class(df$time) = c("POSIXt", "POSIXct")

  # round orientations to nearest 45
  df$angle = roundOrientation(df$orientation)

  # keep only signals from access points
  df = df[df$type == "3",]
  df = df[, "type" != names(df)]

  # drop scanMac, posZ, channel, and type - no info in them
  df = df[, !(names(df) %in% c("scanMac", "posZ"))]

  # drop more unwanted access points
  df = df[df$mac %in% subMacs,]

  # drop channel
  df = df[, "channel" != names(df)]

  return(df)
}

plotBoxplotSignalStrength = function(df) {
  # Box plot signal strength
  #
  # Args:
  #   df: data frame of data to analyze
  #
  oldPar = par(mar = c(3.1, 3.1, 1, 1), mfrow = c(1,1))
  par(mai=c(.8, .8, .5, .25))
  library (lattice)

  print(bwplot(signal ~ factor(angle) | mac, data = df, layout = c(2,1),
               main="Signal Strength Distribution for Access Points",
               xlab="Angle Measured (deg)", ylab="Signal Strengh (dBM)"))
  par(oldPar)
}

plotDensitySignalStrength = function(df) {
  # Density plot signal strength
  #
  # Args:
  #   df: data frame of data to analyze
  #
  oldPar = par(mar = c(3.1, 3.1, 1, 1), mfrow = c(1,1))
  par(mai=c(.8, .8, .5, .25))
  library (lattice)

  print(densityplot( ~ signal | mac + factor(angle), data = df, bw = 0.5, plot.points = FALSE,
        main="Signal Strength Distribution for Access Points",
        xlab="Angle Measured (deg)", ylab="Signal Strengh (dBM)"))
  par(oldPar)
}

plotStdDevSignalStrength = function(df) {
  # Standard Deviation of signal strength average
  #
  # Args:
  #   df: data frame of data to analyze
  #
  oldPar = par(mar = c(3.1, 3.1, 1, 1), mfrow = c(1,1))
  par(mai=c(.8, .8, .5, .25))
  library (lattice)
  breaks = seq(-90, -30, by=5)

  print(bwplot(sdSignal ~ cut(avgSignal, breaks=breaks) | mac, data=df,
               xlab = "Mean Signal (dBM)", ylab = "Signal Standard Deviation (dBM)",
               main = "Standard Deviation of Average Signal Strength from Detector to Access Point",
               cex.main=.8, cex.axis=.8, cex.lab=.8, layout = c(1, 2)))
  par(oldPar)
}


plotSignalMaps = function(macAddresses) {
  # Plot the number of signals per XY location at XY location.
  #
  # Args:
  #   macAddresses: a list of macs to plot signals
  #
  oldPar = par(mar = c(3.1, 3.1, 1, 1), mfrow = c(1,1))
  par(mfrow = c(2, 1), mai=c(.8, .8, .4, .25))

  for (i in macAddresses) {
    # filter data set
    df = offline[offline$mac %in% i, ]
    # location of datapoints filtered
    locDF = with(df, by(df, list(posX, posY), function(x) x))
    # drop locations that were not observed, null
    locDF = locDF[!sapply(locDF, is.null)]

    # determine the number of observations recorded at each location
    locCounts = sapply(locDF, nrow)

    # keep position information with location
    locCounts = sapply(locDF, function(df) c(df[1, c("posX", "posY")], count = nrow(df)))

    # transpose matrix
    locCounts = t(locCounts)
    plot(locCounts, type = "n", xlab = "Position X", ylab = "Position Y",
         main = paste("Total Signals from Detector to Access Point: ", i),
         cex.main=.8, cex.axis=.8, cex.lab=.8)
    text(locCounts, labels = locCounts[, 3], cex = .6, srt = 45)
  }
  par(oldPar)
}

castOnline = function(df) {
  # Cast dataframe of online data so each access point (AP) is in its own column.
  # Matrix is now a 1x7 since we are including rejected AP.
  #
  # Args:
  #   df: online data frame
  #
  keepVars = c("posXY", "posX","posY", "orientation", "angle")
  numOfAPs = length(unique(df$mac))
  byLoc = with(df,
               by(df, list(posXY),
                  function(x) {
                    ans = x[1, keepVars]
                    avgSS = tapply(x$signal, x$mac, mean)
                    y = matrix(avgSS, nrow = 1, ncol = numOfAPs,
                               dimnames = list(ans$posXY, names(avgSS)))
                    cbind(ans, y)
                  }))
  return(do.call("rbind", byLoc))
}

createOfflineSummary = function(df) {
  # In order to examine distribution for all locations, angles, and are two interested APs, we
  # will create a summary statistics for all location-orientation-AP combinations with a new factor.
  # For each combination there are around 100 observations.
  #
  # Args:
  #   df: offline data frame
  #
  df$posXY = paste(df$posX, df$posY, sep="-")

  # create data frames for each combination
  byLocAngleAP = with(df, by(df, list(posXY, angle, mac), function (x) x))

  # summary statistic
  signalSummary = lapply(byLocAngleAP, function(oneLoc) {
    ans = oneLoc[1, ]
    ans$medSignal = median(oneLoc$signal)
    ans$avgSignal = mean(oneLoc$signal)
    ans$num = length(oneLoc$signal)
    ans$sdSignal = sd(oneLoc$signal)
    ans$iqrSignal = IQR(oneLoc$signal)
    ans
  })
  return(do.call("rbind", signalSummary))
}

reshapeSS = function(df,
                     varSignal = "signal",
                     keepVars = c("posXY", "posX", "posY"),
                     sampleAngle = FALSE,
                     refs = seq(0, 315, by=45)) {
  # reshape signal strength help function
  # aggregate signal strengths from these angles and create a data structure similar to onlineSummary
  # Args:
  #   df: dataframe to reshape
  #   varSignal: variable to aggregate
  #   keepVars: variables to retain
  #   sampleAngle: true if we want to select one angle at random from df
  #   refs: angle references
  #
  numOfAPs = length(unique(df$mac))
  byLocation = with(df, by(df, list(posXY),
                             function(x) {
                               # select one angle at random for each location
                               if (sampleAngle) {
                                 x = x[x$angle == sample(refs, size = 1), ]}
                               ans = x[1, keepVars]
                               avgSS = tapply(x[, varSignal], x$mac, mean)
                               y = matrix(avgSS, nrow = 1, ncol = numOfAPs,
                                          dimnames = list(ans$posXY, names(avgSS)))
                               cbind(ans, y)
                             }))
  return(do.call("rbind", byLocation))
}

selectTraininingData = function(newObservationAngle, df = NULL, m = 1){
  # select observations from df to analyze aggregate signal strengths
  # from these angles and create a data structure similar to onlineSummary.
  #
  # Args:
  #   newObservationAngle: the angle of the new observation
  #   df: offline summary data frame
  #   m: number, between 1 and 5, of angles to keep

  # m is the number of angles to keep between 1 and 5
  refs = seq(0, by = 45, length  = 8)
  nearestAngle = roundOrientation(newObservationAngle)

  # handle odd and even m number
  if (m %% 2 == 1)
    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
  else {
    m = m + 1
    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
    if (sign(newObservationAngle - nearestAngle) > -1)
      angles = angles[ -1 ]
    else
      angles = angles[ -m ]
  }
  # map angles to values in refs
  # negative angles and angles greater than 360 are mapped to appropriate angles; e.g., -45 maps to 335 and 405 maps to 45
  angles = angles + nearestAngle
  angles[angles < 0] = angles[ angles < 0 ] + 360
  angles[angles > 360] = angles[ angles > 360 ] - 360
  angles = sort(angles)
  # select observations to analyze
  subset = df[df$angle %in% angles, ]
  # reshape signal strength
  return(reshapeSS(subset, varSignal = "avgSignal"))
}

findNN = function(newSignal, trainingSubset) {
  # want to look the distance in terms of signal strengths from these training data to the new
  # data point. we need to calculate teh distrance from the new point to all observations in the
  # training set with findNN().
  # returns locations of the training observations in order of closeness to the new observation's signal strength.
  #
  # Args:
  #   newSignal: signal of new observation
  #   trainingSubset: training data to find neighbors
  # Returns:
  #   training neighbors
  #
  cols = length(trainingSubset)
  diffs = apply(trainingSubset[ , 4:cols], 1, function(x) x - newSignal)
  dists = apply(diffs, 2, function(x) sqrt(sum(x^2)) )
  #closest = order(dists)
  closest = cbind(trainingSubset[, 1:3 ], dists)
  return(closest[order(dists),])
  #return(trainingSubset[closest, 1:3 ])
}

predXY = function(newSignals, newAngles, training, numAngles = 1, k = 3, weighted=FALSE){
  # Predict the XY coordinates given a list of signals along with their angles measured and training data.
  # k neighbors will be found to make the prediction of coordinate.
  #
  # Args:
  #   newSignals: list of signals to predict
  #   newAngles: list of angles for signals to predict
  #   trainingData: data needed for k-nn
  #   numAngles: angles we want to use for prediction
  #   k: number of neighbors to use for prediction
  #   weighted: if TRUE, distances to neighbors will be used to weight XY for each neighbor to determine
  #             location.
  #
  closeXY = list(length = nrow(newSignals))

  for (i in 1:nrow(newSignals)) {
    trainSS = selectTraininingData(newAngles[i], training, m = numAngles)
    closeXY[[i]] = findNN(newSignal = as.numeric(newSignals[i, ]), trainSS)
  }
  # for some k of nearest neighbors, simply average the first k locations
  # could have used weights in the average that are inversely proportional to the distance in signal strength
  # from the test observation. will need to call findNN() to get distance to point. the weights
  # are 1/d / sum(1/d).
  # could also use a different metric besides Euclidean like Manhattan.
  # could use medians instead of averages when combining neighbors if the distribution of values are quite skewed.
  if (!weighted) {
    estXY = lapply(closeXY, function(x) sapply(x[ , 2:3], function(x) mean(x[1:k])))
  } else {
    # sum X and Y weighted neighbor values.
    estXY = lapply(closeXY, function(x) {
      wt = (1/x[1:k, 4])/sum(1/x[1:k, 4])
      xy = cbind(x[1:k,], wt)
      # sum weighted neighbors
      return(colSums(xy[1:4, 2:3] * xy[1:4, 4]))
    })
  }
  return(do.call("rbind", estXY))
}

calcError = function(estXY, actualXY) {
  # compare fit numerically with sum of squared errors
  #
  # Args:
  #   estXY:
  #   actualXY:
  # Returns:
  #   calculated residual sum of squares
  return(sum(rowSums((estXY - actualXY) ^ 2)))
}

plotSSErrors = function(err, K){
  # Plot results as sum of squared errors as function of k
  #
  # Args:
  #   err: Error array
  #   K: number of neighbors
  #

  oldPar = par(mar = c(3.1, 3.1, 1, 1), mfrow = c(1,1))
  par(mai=c(.8, .8, .4, .25))

  plot(y = err, x = (1:K),  type = "l", lwd= 2, ylim = c(900, 2100), cex.main=.8, cex.axis=.8, cex.lab=.8,
       xlab = "Number of Neighbors",
       ylab = "Sum of Squared Errors",
       main = "Cross Validation Section of k")

  rmseMin = min(err)
  kMin = which(err == rmseMin)[1]
  segments(x0 = 0, x1 = kMin, y0 = rmseMin, col = gray(0.4), lty = 2, lwd = 2)
  segments(x0 = kMin, x1 = kMin, y0 = 800,  y1 = rmseMin, col = grey(0.4), lty = 2, lwd = 2)
  text(x = kMin - 2, y = rmseMin + 40, label = as.character(round(rmseMin)), col = grey(0.4), cex = .6)

  par(oldPar)
}

wt_signals <- function(ByAvgSig){
  
  # Name: wt_signals
  # Create weighted data
  #
  # Args:
  #   ByAvgSig:    estimate XY line segment
  #   
  # Returns:
  #   log_ang by weighted_signals matrix
  
  # calculate signals
  signals <- select(ByAvgSig, -posXY, -posX, -posY, -angle) 
  
  # calculate log_ang
  loc_ang <- select(ByAvgSig, posXY, posX, posY, angle)
  
  # calculate weighted_signals 
  weighted_signals <- (1/signals) / rowSums(1/signals)
  
  return(cbind(loc_ang, weighted_signals))
}
```
